{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katifrahim/Reducing-the-computational-demand-of-3D-CNNs/blob/main/Pruning_3D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_n4KY5_1Sj5",
        "outputId": "7169ff24-aa8b-4377-a725-8b47aa4734ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=83a12d4ff55866149a6ebe3d9221b0c51f9073c0de3c958bf1fa14c1ff837144\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4-FemtA1bAX",
        "outputId": "2e871cc9-0cf9-44d9-fdda-e360176e9ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import GPUtil\n",
        "from tabulate import tabulate\n",
        "import copy\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM4RsMPG1kA-"
      },
      "outputs": [],
      "source": [
        "# Custom dataset and dataloader for the 3D CNN\n",
        "\n",
        "class VoxelGridDataset(Dataset):\n",
        "  def __init__(self, root_dir, mode, transform=None):\n",
        "    self.root_dir = root_dir\n",
        "    self.mode = mode\n",
        "    self.transform = transform\n",
        "    self.file_paths = []\n",
        "    self.categories = []\n",
        "    self.category_to_index = {}\n",
        "    self.index_to_category = {}\n",
        "\n",
        "    categories = os.listdir(root_dir)\n",
        "    categories.sort()\n",
        "\n",
        "    for idx, category in enumerate(categories):\n",
        "      self.category_to_index[category] = idx\n",
        "      self.index_to_category[idx] = category\n",
        "\n",
        "    for category in categories:\n",
        "      category_path = os.path.join(root_dir, category)\n",
        "      category_mode_path = os.path.join(category_path, mode)\n",
        "      for file in os.listdir(category_mode_path):\n",
        "        self.file_paths.append(os.path.join(category_mode_path, file))\n",
        "        self.categories.append(category)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.file_paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    voxel_grid_array = np.load(self.file_paths[idx])['arr_0']\n",
        "    category = self.categories[idx]\n",
        "    category_idx = self.category_to_index[category]\n",
        "\n",
        "    if self.transform:\n",
        "      voxel_grid_array = self.transform(voxel_grid_array)\n",
        "\n",
        "    return voxel_grid_array, category_idx\n",
        "\n",
        "class ToTensor(object):\n",
        "  def __call__(self, voxel_grid_array):\n",
        "    return torch.from_numpy(voxel_grid_array).float()\n",
        "\n",
        "root_dir = '/content/drive/MyDrive/ModelNet10_arrays'\n",
        "\n",
        "train_dataset = VoxelGridDataset(root_dir, mode='train', transform=ToTensor())\n",
        "test_dataset = VoxelGridDataset(root_dir, mode='test', transform=ToTensor())\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # shuffle is set true to prevent overfitting\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # shuffle is set false for accurate and consistent evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVzXrTaw1k0s",
        "outputId": "e85787e2-c2c7-4f24-ba37-0b279bd25816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhTVKN2Z1ovM",
        "outputId": "3a0b65b7-4490-4adc-daf1-6c12296f1f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Progress: Epoch 1 - 1.6036081182660988 % Done!\n",
            "Progress: Epoch 1 - 3.2072162365321977 % Done!\n",
            "Progress: Epoch 1 - 4.810824354798296 % Done!\n",
            "Progress: Epoch 1 - 6.414432473064395 % Done!\n",
            "Progress: Epoch 1 - 8.018040591330495 % Done!\n",
            "Progress: Epoch 1 - 9.621648709596592 % Done!\n",
            "Progress: Epoch 1 - 11.22525682786269 % Done!\n",
            "Progress: Epoch 1 - 12.82886494612879 % Done!\n",
            "Progress: Epoch 1 - 14.432473064394888 % Done!\n",
            "Progress: Epoch 1 - 16.03608118266099 % Done!\n",
            "Progress: Epoch 1 - 17.639689300927085 % Done!\n",
            "Progress: Epoch 1 - 19.243297419193183 % Done!\n",
            "Progress: Epoch 1 - 20.846905537459286 % Done!\n",
            "Progress: Epoch 1 - 22.45051365572538 % Done!\n",
            "Progress: Epoch 1 - 24.05412177399148 % Done!\n",
            "Progress: Epoch 1 - 25.65772989225758 % Done!\n",
            "Progress: Epoch 1 - 27.261338010523676 % Done!\n",
            "Progress: Epoch 1 - 28.864946128789775 % Done!\n",
            "Progress: Epoch 1 - 30.468554247055874 % Done!\n",
            "Progress: Epoch 1 - 32.07216236532198 % Done!\n",
            "Progress: Epoch 1 - 33.675770483588074 % Done!\n",
            "Progress: Epoch 1 - 35.27937860185417 % Done!\n",
            "Progress: Epoch 1 - 36.88298672012027 % Done!\n",
            "Progress: Epoch 1 - 38.48659483838637 % Done!\n",
            "Progress: Epoch 1 - 40.09020295665246 % Done!\n",
            "Progress: Epoch 1 - 41.69381107491857 % Done!\n",
            "Progress: Epoch 1 - 43.297419193184666 % Done!\n",
            "Progress: Epoch 1 - 44.90102731145076 % Done!\n",
            "Progress: Epoch 1 - 46.50463542971686 % Done!\n",
            "Progress: Epoch 1 - 48.10824354798296 % Done!\n",
            "Progress: Epoch 1 - 49.71185166624906 % Done!\n",
            "Progress: Epoch 1 - 51.31545978451516 % Done!\n",
            "Progress: Epoch 1 - 52.91906790278126 % Done!\n",
            "Progress: Epoch 1 - 54.52267602104735 % Done!\n",
            "Progress: Epoch 1 - 56.126284139313455 % Done!\n",
            "Progress: Epoch 1 - 57.72989225757955 % Done!\n",
            "Progress: Epoch 1 - 59.33350037584565 % Done!\n",
            "Progress: Epoch 1 - 60.93710849411175 % Done!\n",
            "Progress: Epoch 1 - 62.54071661237784 % Done!\n",
            "Progress: Epoch 1 - 64.14432473064396 % Done!\n",
            "Progress: Epoch 1 - 65.74793284891005 % Done!\n",
            "Progress: Epoch 1 - 67.35154096717615 % Done!\n",
            "Progress: Epoch 1 - 68.95514908544224 % Done!\n",
            "Progress: Epoch 1 - 70.55875720370834 % Done!\n",
            "Progress: Epoch 1 - 72.16236532197445 % Done!\n",
            "Progress: Epoch 1 - 73.76597344024054 % Done!\n",
            "Progress: Epoch 1 - 75.36958155850664 % Done!\n",
            "Progress: Epoch 1 - 76.97318967677273 % Done!\n",
            "Progress: Epoch 1 - 78.57679779503883 % Done!\n",
            "Progress: Epoch 1 - 80.18040591330492 % Done!\n",
            "Progress: Epoch 1 - 81.78401403157103 % Done!\n",
            "Progress: Epoch 1 - 83.38762214983714 % Done!\n",
            "Progress: Epoch 1 - 84.99123026810324 % Done!\n",
            "Progress: Epoch 1 - 86.59483838636933 % Done!\n",
            "Progress: Epoch 1 - 88.19844650463543 % Done!\n",
            "Progress: Epoch 1 - 89.80205462290152 % Done!\n",
            "Progress: Epoch 1 - 91.40566274116763 % Done!\n",
            "Progress: Epoch 1 - 93.00927085943373 % Done!\n",
            "Progress: Epoch 1 - 94.61287897769982 % Done!\n",
            "Progress: Epoch 1 - 96.21648709596592 % Done!\n",
            "Progress: Epoch 1 - 97.82009521423201 % Done!\n",
            "Progress: Epoch 1 - 99.42370333249812 % Done!\n",
            "Progress: Epoch 1 - 100.0 % Done!\n",
            "Progress: Epoch 2 - 1.6036081182660988 % Done!\n",
            "Progress: Epoch 2 - 3.2072162365321977 % Done!\n",
            "Progress: Epoch 2 - 4.810824354798296 % Done!\n",
            "Progress: Epoch 2 - 6.414432473064395 % Done!\n",
            "Progress: Epoch 2 - 8.018040591330495 % Done!\n",
            "Progress: Epoch 2 - 9.621648709596592 % Done!\n",
            "Progress: Epoch 2 - 11.22525682786269 % Done!\n",
            "Progress: Epoch 2 - 12.82886494612879 % Done!\n",
            "Progress: Epoch 2 - 14.432473064394888 % Done!\n",
            "Progress: Epoch 2 - 16.03608118266099 % Done!\n",
            "Progress: Epoch 2 - 17.639689300927085 % Done!\n",
            "Progress: Epoch 2 - 19.243297419193183 % Done!\n",
            "Progress: Epoch 2 - 20.846905537459286 % Done!\n",
            "Progress: Epoch 2 - 22.45051365572538 % Done!\n",
            "Progress: Epoch 2 - 24.05412177399148 % Done!\n",
            "Progress: Epoch 2 - 25.65772989225758 % Done!\n",
            "Progress: Epoch 2 - 27.261338010523676 % Done!\n",
            "Progress: Epoch 2 - 28.864946128789775 % Done!\n",
            "Progress: Epoch 2 - 30.468554247055874 % Done!\n",
            "Progress: Epoch 2 - 32.07216236532198 % Done!\n",
            "Progress: Epoch 2 - 33.675770483588074 % Done!\n",
            "Progress: Epoch 2 - 35.27937860185417 % Done!\n",
            "Progress: Epoch 2 - 36.88298672012027 % Done!\n",
            "Progress: Epoch 2 - 38.48659483838637 % Done!\n",
            "Progress: Epoch 2 - 40.09020295665246 % Done!\n",
            "Progress: Epoch 2 - 41.69381107491857 % Done!\n",
            "Progress: Epoch 2 - 43.297419193184666 % Done!\n",
            "Progress: Epoch 2 - 44.90102731145076 % Done!\n",
            "Progress: Epoch 2 - 46.50463542971686 % Done!\n",
            "Progress: Epoch 2 - 48.10824354798296 % Done!\n",
            "Progress: Epoch 2 - 49.71185166624906 % Done!\n",
            "Progress: Epoch 2 - 51.31545978451516 % Done!\n",
            "Progress: Epoch 2 - 52.91906790278126 % Done!\n",
            "Progress: Epoch 2 - 54.52267602104735 % Done!\n",
            "Progress: Epoch 2 - 56.126284139313455 % Done!\n",
            "Progress: Epoch 2 - 57.72989225757955 % Done!\n",
            "Progress: Epoch 2 - 59.33350037584565 % Done!\n",
            "Progress: Epoch 2 - 60.93710849411175 % Done!\n",
            "Progress: Epoch 2 - 62.54071661237784 % Done!\n",
            "Progress: Epoch 2 - 64.14432473064396 % Done!\n",
            "Progress: Epoch 2 - 65.74793284891005 % Done!\n",
            "Progress: Epoch 2 - 67.35154096717615 % Done!\n",
            "Progress: Epoch 2 - 68.95514908544224 % Done!\n",
            "Progress: Epoch 2 - 70.55875720370834 % Done!\n",
            "Progress: Epoch 2 - 72.16236532197445 % Done!\n",
            "Progress: Epoch 2 - 73.76597344024054 % Done!\n",
            "Progress: Epoch 2 - 75.36958155850664 % Done!\n",
            "Progress: Epoch 2 - 76.97318967677273 % Done!\n",
            "Progress: Epoch 2 - 78.57679779503883 % Done!\n",
            "Progress: Epoch 2 - 80.18040591330492 % Done!\n",
            "Progress: Epoch 2 - 81.78401403157103 % Done!\n",
            "Progress: Epoch 2 - 83.38762214983714 % Done!\n",
            "Progress: Epoch 2 - 84.99123026810324 % Done!\n",
            "Progress: Epoch 2 - 86.59483838636933 % Done!\n",
            "Progress: Epoch 2 - 88.19844650463543 % Done!\n",
            "Progress: Epoch 2 - 89.80205462290152 % Done!\n",
            "Progress: Epoch 2 - 91.40566274116763 % Done!\n",
            "Progress: Epoch 2 - 93.00927085943373 % Done!\n",
            "Progress: Epoch 2 - 94.61287897769982 % Done!\n",
            "Progress: Epoch 2 - 96.21648709596592 % Done!\n",
            "Progress: Epoch 2 - 97.82009521423201 % Done!\n",
            "Progress: Epoch 2 - 99.42370333249812 % Done!\n",
            "Progress: Epoch 2 - 100.0 % Done!\n",
            "Finished training!\n",
            "Testing...\n",
            "Progress: 7.048458149779736 % Done!\n",
            "Progress: 14.096916299559473 % Done!\n",
            "Progress: 21.145374449339208 % Done!\n",
            "Progress: 28.193832599118945 % Done!\n",
            "Progress: 35.24229074889868 % Done!\n",
            "Progress: 42.290748898678416 % Done!\n",
            "Progress: 49.33920704845815 % Done!\n",
            "Progress: 56.38766519823789 % Done!\n",
            "Progress: 63.436123348017624 % Done!\n",
            "Progress: 70.48458149779736 % Done!\n",
            "Progress: 77.5330396475771 % Done!\n",
            "Progress: 84.58149779735683 % Done!\n",
            "Progress: 91.62995594713657 % Done!\n",
            "Progress: 98.6784140969163 % Done!\n",
            "Progress: 100.0 % Done!\n",
            "Finished testing! \n",
            "\n",
            "Accuracy: 79.07488986784142% | GPU utilization: 0.8322916666666667%\n"
          ]
        }
      ],
      "source": [
        "# Custom 3D CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(CNN, self).__init__()\n",
        "      self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "      self.conv1 = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "      self.conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.fc1 = nn.Linear(32 * 25 * 25 * 25, 128)\n",
        "      self.fc2 = nn.Linear(128, 10)  # ModelNet10 Dataset contains 10 different labels\n",
        "    def forward(self, x):\n",
        "      # input 1x100x100x100 output 1x50x50x50\n",
        "      x = self.pool(x)\n",
        "      # input 1x50x50x50 output 16x50x50x50\n",
        "      x = self.relu(self.conv1(x))\n",
        "      # input 16x50x50x50 output 32x50x50x50\n",
        "      x = self.relu(self.conv2(x))\n",
        "      # input 32x50x50x50 output 32x25x25x25\n",
        "      x = self.pool(x)\n",
        "      # input 32x25x25x25 output 500000\n",
        "      x = self.flatten(x)\n",
        "      # input 500000 output 128\n",
        "      x = self.relu(self.fc1(x))\n",
        "      # input 128 output 10\n",
        "      x = self.fc2(x)\n",
        "      return x\n",
        "\n",
        "# Instantiating\n",
        "model = CNN()\n",
        "model.to(device)\n",
        "\n",
        "# Training\n",
        "print(\"Training...\")\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "epochs = 2\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  samples = 0\n",
        "  for data, labels in train_dataloader:\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    data = data.unsqueeze(1)\n",
        "    predicted_labels = model(data)\n",
        "    loss = loss_function(predicted_labels, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    samples += len(labels)\n",
        "    print(f'Progress: Epoch {epoch+1} - {(samples/len(train_dataset))*100} % Done!')\n",
        "print('Finished training!')\n",
        "\n",
        "# Testing\n",
        "print(\"Testing...\")\n",
        "total_samples = 0\n",
        "correct_predictions = 0\n",
        "gpu_utilizations = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for data, labels in test_dataloader:\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "    data = data.unsqueeze(1)\n",
        "    torch.cuda.synchronize()\n",
        "    predicted_labels = model(data)\n",
        "    torch.cuda.synchronize()\n",
        "    gpu_utilization = GPUtil.getGPUs()[0].load * 100\n",
        "    gpu_utilizations.append(gpu_utilization)\n",
        "    predicted_labels = predicted_labels.argmax(dim=1)\n",
        "    total_samples += len(labels)\n",
        "    for i in range(len(labels)):\n",
        "      if predicted_labels[i] == labels[i]:\n",
        "        correct_predictions += 1\n",
        "    print(f'Progress: {(total_samples/len(test_dataset))*100} % Done!')\n",
        "print('Finished testing! \\n')\n",
        "\n",
        "# Results\n",
        "average_gpu_utilization_batch = sum(gpu_utilizations) / len(gpu_utilizations)\n",
        "average_gpu_utilization_inference = average_gpu_utilization_batch / batch_size\n",
        "accuracy = (correct_predictions / total_samples) * 100\n",
        "\n",
        "print(f\"Accuracy: {accuracy}% | GPU utilization: {average_gpu_utilization_inference}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PeEUNHTO15Hn",
        "outputId": "190f5b56-2ad8-4a80-f9c9-779abd726cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1 norm weight pruning \n",
            "\n",
            "Pruning percentage for each conv layer: 10.0% | Accuracy: 78.9647577092511% | GPU utilization: 0.7770833333333333%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 20.0% | Accuracy: 79.07488986784142% | GPU utilization: 0.6083333333333333%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 30.000000000000004% | Accuracy: 79.07488986784142% | GPU utilization: 0.6729166666666667%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 40.0% | Accuracy: 78.9647577092511% | GPU utilization: 0.6854166666666667%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 50.0% | Accuracy: 78.8546255506608% | GPU utilization: 0.8239583333333333%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 60.0% | Accuracy: 78.41409691629956% | GPU utilization: 0.21666666666666667%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      60 |        78.4141 |                            0.216667 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 70.0% | Accuracy: 78.63436123348018% | GPU utilization: 0.7375%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      60 |        78.4141 |                            0.216667 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      70 |        78.6344 |                            0.7375   |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 80.0% | Accuracy: 73.568281938326% | GPU utilization: 0.6520833333333333%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      60 |        78.4141 |                            0.216667 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      70 |        78.6344 |                            0.7375   |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      80 |        73.5683 |                            0.652083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 89.99999999999999% | Accuracy: 65.7488986784141% | GPU utilization: 0.36041666666666666%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      60 |        78.4141 |                            0.216667 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      70 |        78.6344 |                            0.7375   |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      80 |        73.5683 |                            0.652083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      90 |        65.7489 |                            0.360417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "Pruning percentage for each conv layer: 99.99999999999999% | Accuracy: 11.013215859030836% | GPU utilization: 0.515625%\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|   Pruning percentage per conv layer (%) |   Accuracy (%) |   GPU utilization per inference (%) |\n",
            "+=========================================+================+=====================================+\n",
            "|                                      10 |        78.9648 |                            0.777083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      20 |        79.0749 |                            0.608333 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      30 |        79.0749 |                            0.672917 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      40 |        78.9648 |                            0.685417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      50 |        78.8546 |                            0.823958 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      60 |        78.4141 |                            0.216667 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      70 |        78.6344 |                            0.7375   |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      80 |        73.5683 |                            0.652083 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                      90 |        65.7489 |                            0.360417 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n",
            "|                                     100 |        11.0132 |                            0.515625 |\n",
            "+-----------------------------------------+----------------+-------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Iterative L1 norm weight pruning\n",
        "\n",
        "print(\"L1 norm weight pruning \\n\")\n",
        "\n",
        "pruning_epochs = 10\n",
        "training_epochs = 1\n",
        "pruning_ratio = 0.0\n",
        "results_array = []\n",
        "for pruning_epoch in range(pruning_epochs):\n",
        "\n",
        "  pruning_model = copy.deepcopy(model)\n",
        "  pruning_model.to(device)\n",
        "  pruning_ratio += 0.1\n",
        "\n",
        "  # Pruning\n",
        "  for module in pruning_model.modules():\n",
        "    if isinstance(module, nn.Conv3d):\n",
        "      prune.l1_unstructured(module, name='weight', amount=pruning_ratio)\n",
        "      prune.remove(module, \"weight\")\n",
        "\n",
        "  # Testing\n",
        "  total_samples = 0\n",
        "  correct_predictions = 0\n",
        "  gpu_utilizations = []\n",
        "  pruning_model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, labels in test_dataloader:\n",
        "      data, labels = data.to(device), labels.to(device)\n",
        "      data = data.unsqueeze(1)\n",
        "      torch.cuda.synchronize()\n",
        "      predicted_labels = pruning_model(data)\n",
        "      torch.cuda.synchronize()\n",
        "      gpu_utilization = GPUtil.getGPUs()[0].load * 100\n",
        "      gpu_utilizations.append(gpu_utilization)\n",
        "      predicted_labels = predicted_labels.argmax(dim=1)\n",
        "      total_samples += len(labels)\n",
        "      for i in range(len(labels)):\n",
        "        if predicted_labels[i] == labels[i]:\n",
        "          correct_predictions +=1\n",
        "\n",
        "  # Results\n",
        "  pruning_percentage = pruning_ratio*100\n",
        "  accuracy =  correct_predictions/ total_samples * 100\n",
        "  average_gpu_utilization_batch = sum(gpu_utilizations) / len(gpu_utilizations)\n",
        "  average_gpu_utilization_inference = average_gpu_utilization_batch / batch_size\n",
        "  array = [pruning_percentage, accuracy, average_gpu_utilization_inference]\n",
        "  results_array.append(array)\n",
        "\n",
        "  # Displaying the results\n",
        "  print(f\"Pruning percentage for each conv layer: {pruning_percentage}% | Accuracy: {accuracy}% | GPU utilization: {average_gpu_utilization_inference}%\")\n",
        "  headers_array = ['Pruning percentage per conv layer (%)', 'Accuracy (%)', 'GPU utilization per inference (%)']\n",
        "  table = tabulate(results_array, headers_array, tablefmt=\"grid\")\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZmK0aPg5O3D"
      },
      "outputs": [],
      "source": [
        "# Iterative L1 norm filter pruning\n",
        "\n",
        "print(\"L1 norm filter pruning \\n\")\n",
        "\n",
        "pruning_epochs = 10\n",
        "training_epochs = 1\n",
        "pruning_ratio = 0.0\n",
        "results_array = []\n",
        "for pruning_epoch in range(pruning_epochs):\n",
        "\n",
        "  pruning_model = copy.deepcopy(model)\n",
        "  pruning_model.to(device)\n",
        "  pruning_ratio += 0.1\n",
        "\n",
        "  # Pruning\n",
        "  for module in pruning_model.modules():\n",
        "    if isinstance(module, nn.Conv3d):\n",
        "      prune.ln_structured(module, name='weight', amount=pruning_ratio, n=1, dim=0)\n",
        "      prune.remove(module, \"weight\")\n",
        "\n",
        "  # Testing\n",
        "  total_samples = 0\n",
        "  correct_predictions = 0\n",
        "  gpu_utilizations = []\n",
        "  pruning_model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, labels in test_dataloader:\n",
        "      data, labels = data.to(device), labels.to(device)\n",
        "      data = data.unsqueeze(1)\n",
        "      torch.cuda.synchronize()\n",
        "      predicted_labels = pruning_model(data)\n",
        "      torch.cuda.synchronize()\n",
        "      gpu_utilization = GPUtil.getGPUs()[0].load * 100\n",
        "      gpu_utilizations.append(gpu_utilization)\n",
        "      predicted_labels = predicted_labels.argmax(dim=1)\n",
        "      total_samples += len(labels)\n",
        "      for i in range(len(labels)):\n",
        "        if predicted_labels[i] == labels[i]:\n",
        "          correct_predictions +=1\n",
        "\n",
        "  # Results\n",
        "  pruning_percentage = pruning_ratio*100\n",
        "  accuracy =  correct_predictions/ total_samples * 100\n",
        "  average_gpu_utilization_batch = sum(gpu_utilizations) / len(gpu_utilizations)\n",
        "  average_gpu_utilization_inference = average_gpu_utilization_batch / batch_size\n",
        "  array = [pruning_percentage, accuracy, average_gpu_utilization_inference]\n",
        "  results_array.append(array)\n",
        "\n",
        "  # Displaying the results\n",
        "  print(f\"Pruning percentage for each conv layer: {pruning_percentage}% | Accuracy: {accuracy}% | GPU utilization: {average_gpu_utilization_inference}%\")\n",
        "  headers_array = ['Pruning percentage per conv layer (%)', 'Accuracy (%)', 'GPU utilization per inference (%)']\n",
        "  table = tabulate(results_array, headers_array, tablefmt=\"grid\")\n",
        "  print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABORMEH7nOmj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}